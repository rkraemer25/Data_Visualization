{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5efb0889",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Data Visualization: Live Session 1\n",
    "\n",
    "## Session Overview\n",
    "\n",
    "+ Cource Overview\n",
    "    - Expectations\n",
    "    - Syllabus\n",
    "    - Assignments\n",
    "\n",
    "\n",
    "+ Introductions\n",
    "    - Where are you (geographically)?\n",
    "    - What kind of visualization tools have you used?\n",
    "    \n",
    "\n",
    "+ A thrilling review of some essential concepts and packages\n",
    "    - \\*args and \\*\\*kwargs\n",
    "    - numpy\n",
    "    - pandas\n",
    "\n",
    "\n",
    "+ In-class activity\n",
    "\n",
    "\n",
    "+ Overview of Assignment 1\n",
    "\n",
    "\n",
    "+ Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1467b93b",
   "metadata": {},
   "source": [
    "## Packages you'll need for this course:\n",
    "_Note that geopandas can be tricky to install._\n",
    "\n",
    "_I've posted a requirements.txt file to the files section on 2DU that should build a good venv for this course._\n",
    "+ numpy\n",
    "+ pandas\n",
    "+ matplotlib\n",
    "+ seaborn\n",
    "+ geopy\n",
    "+ folium\n",
    "+ shapely\n",
    "+ geopandas\n",
    "+ yfinance\n",
    "+ ipykernel \n",
    "+ plotly\n",
    "+ dash"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5e5157",
   "metadata": {},
   "source": [
    "### Adding Virtual Environment as an ipykernel\n",
    "\n",
    "Opening a Jupyter session will utilize the default Python3 ipykernel. However, you can add your virtual envvironment as a kernel to use in Jupyter.\n",
    "\n",
    " - Activate the virtual environment you want to add.\n",
    " - From your virtual environment directory, run pip install ipykernel\n",
    " - Run: ipython kernel install --user --name=name_of_venv\n",
    " - To uninstall a kernel run: jupyter kernelspec uninstall name_of_venv\n",
    " - When you open a Jupyter session you should now be able to select the kernel you've created from your virtual environment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1d1b708",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Charles Joseph Minard's map of Napoleon's Russian Campaign of 1812\n",
    "<img src=\"https://www.researchgate.net/profile/Robert-Strohmaier/publication/277098952/figure/fig5/AS:294635642605574@1447258019690/Charles-Joseph-Minards-visualization-of-Napoleons-Russian-campaign-of-1812-Friendly.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4e2225",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Edward Tufte\n",
    "<img src=\"http://prod-upp-image-read.ft.com/6e52bc30-f4d3-11e2-a62e-00144feabdc0\" width=\"400\" height=\"300\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e6d6e6",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "vid = YouTubeVideo(\"jbkSRLYSojo\", width=900, height=500, allow_autoplay=False)\n",
    "display(vid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc3a313",
   "metadata": {},
   "source": [
    "### *args and **kwargs review\n",
    "a single * is the unpacking operator for iterables\n",
    "\n",
    "a double ** is the unpacking operator for dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f07813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# suppose we want to create a function to sum to variables\n",
    "def sum_it(a, b):\n",
    "    return a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5c3cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now suppose we want to be able to extend this function to be able\n",
    "# to sum n digits.\n",
    "def sum_it(int_list):\n",
    "    total = 0\n",
    "    for i in int_list:\n",
    "        total += i\n",
    "    return total\n",
    "\n",
    "some_ints = [1, 2, 3, 4]\n",
    "print(sum_it(some_ints))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07b47c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This works nicely, but we need to put the elements to sum in a list\n",
    "# before we call the function on them.\n",
    "\n",
    "def sum_it(*args):\n",
    "    total = 0\n",
    "    for i in args:\n",
    "        total += i\n",
    "    return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0848cb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we're not passing a list.  We're passing positional arguments.\n",
    "# our function takes these arguments and packs them into an iterable object (tuple)\n",
    "# called args. args is not a keyword we could just as well say *numbers.\n",
    "# The unpacking operator * is the important part.\n",
    "print(sum_it(1, 2, 3, 4, 5, 6, 18))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c55a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# **kwargs is similar to *args, but it accepts keyword arguments instead\n",
    "# of positional arguments.\n",
    "def multiple_ops(**kwargs):\n",
    "    initial_sum = kwargs['add_1'] + kwargs['add_2']\n",
    "    try:\n",
    "        if kwargs['operation'] == 'div':\n",
    "            return initial_sum / kwargs['mult_div']\n",
    "    except KeyError:\n",
    "        return initial_sum * kwargs['mult_div']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8ec361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we pass a dictionary to our function (although, note that\n",
    "# it isn't defined with curly braces).  Think of the keywords as keys and the values\n",
    "# as values.\n",
    "multiple_ops(add_1=7, add_2=8, mult_div=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c9660bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "multiple_ops(add_1=7, add_2=8, mult_div=2, operation='div')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5841f58",
   "metadata": {},
   "source": [
    "#### Again, the name kwargs is just a convention. We're really concerned with the ** unpacking operator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff3522a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# An example using *args and **kwargs\n",
    "# This function takes *args and *kwargs as parameters.\n",
    "# The function loops through all arg values and multiplies them to get iterations.\n",
    "# We then loop over the range of iterations and if the iterator is even\n",
    "# we print kwargs values else we print kwargs keys.\n",
    "\n",
    "def do_something(*args, **kwargs):\n",
    "    iterations = 1\n",
    "    for arg in args:\n",
    "        iterations *= arg\n",
    "\n",
    "    for i in range(iterations):\n",
    "        if i % 2 == 0:\n",
    "            print(f'{i} is even')\n",
    "            print(kwargs.values())\n",
    "        else:\n",
    "            print(f'{i} is odd')\n",
    "            print(kwargs.keys())\n",
    "\n",
    "do_something(1, 2, 3, 4, 5, foo = 'hello', bar = 'hi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7501f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# what happens if I try to specify the key word arguments before the positional arguments?\n",
    "do_something(bar = 'hi', foo = 'hello', 1, 2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c323a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# another function using *kwargs\n",
    "def p_func(**kwargs):\n",
    "    for i in kwargs.values():\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6becf504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice the error generated when we call the function on the following input.\n",
    "p_func('a', 'b', 'c', 'd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59074f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_func(arg1 = 'a', arg2 = 'b', arg3 = 'c', arg4 = 'b')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e541ddf",
   "metadata": {},
   "source": [
    "#### Writing functions with standard arguments, *args and *kwargs\n",
    "Note that the order is critical here.\n",
    "Standard arguments precede *args, which precede **kwargs.\n",
    "\n",
    "Note that the single unpacking operator (\\*) can be used on any iterable.\n",
    "The ** unpacking operator can only be used on dicts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e3f38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to get a better sense of what the unpacking operator does\n",
    "# notice how calling print on the list prints the brackets, commas and quotes (the list itself)\n",
    "print(['foo', 'bar'])\n",
    "# calling print on the unpacked list prints just the list content\n",
    "print(*['foo', 'bar'])\n",
    "\n",
    "# this is the same as calling print with two arguments...\n",
    "print('foo', 'bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a077dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# passing unpacked args to a function with a specified number of arguments\n",
    "def print_something(a, b):\n",
    "    print(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780a9af3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this allows us to pass in the two required parameters with unpacking\n",
    "print_something(*['foo', 'bar'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02cc381",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we're unpacking too many values\n",
    "print_something(*['foo', 'bar', 'norf'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4919eef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# another printing function using *args\n",
    "def print_something(*args):\n",
    "    hold = ''\n",
    "    for i in args:\n",
    "        hold += str(i) + ' '\n",
    "    print(hold)\n",
    "\n",
    "# consider passing multiple lists to the above function.\n",
    "# the unpacking operator in *args will treat these as a tuple of lists.\n",
    "\n",
    "# we can use unpacking operators on our function inputs as well as within the function.\n",
    "# Here we use multiple unpacking operators to unpack three lists and pass those values\n",
    "# as *args...they will then be packed into a tuple and further unpacked within the function.\n",
    "print_something(*[1, 2, 3], *[4, 5, 6], *[7, 8, 9])\n",
    "\n",
    "# without the additional level of unpacking we're just concatenating the lists\n",
    "print_something([1, 2, 3], [4, 5, 6], [7, 8, 9])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa8969f",
   "metadata": {},
   "source": [
    "### Now a bit of numpy review.\n",
    "\n",
    "Matplotlib uses the numpy ndarray data structure, so it's important to have a good grasp on these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2687fd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# numpy's array method takes any list, tuple or array-like object and converts it to an ndarray\n",
    "\n",
    "an_array = np.array([i for i in range(10)])\n",
    "print(an_array)\n",
    "print(type(an_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8299300f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nested arrays are arrays that have arrays as values\n",
    "\n",
    "# a 0-D array is just a scalar...each value in a 1D array is a 0-D array itself\n",
    "scalar = np.array(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e83870a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a 1-D array has scalars as its elements.  Think of a single vector of scalars.\n",
    "basic_array = np.array([1, 2, 3, 4, 5])\n",
    "print(basic_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770798d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a 2-D array is just an array of arrays. Think of a matrix or table.\n",
    "two_dim_array = np.array([[1, 2, 3], [4, 5, 6]])\n",
    "print(two_dim_array)\n",
    "\n",
    "# we can evaluate the shape attribute of ndarrays as well\n",
    "print(two_dim_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c88ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a 3-D array has 2-D array elements.\n",
    "three_dim_array = np.array([[[2, 4, 6], [8, 10, 12]], [[14, 16, 18], [20, 22, 24]]])\n",
    "print(three_dim_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30df6725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the ndim attribute gives the number of dimensions in an ndarray\n",
    "print(three_dim_array.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7b17c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that ndarrays can have any number of dimensions.\n",
    "# np.array() takes an optional argument ndmin to specify dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140ce1aa",
   "metadata": {},
   "source": [
    "### Indexing ndarrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5983c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to index 2D arrays we use comma separated values to address dimension and index\n",
    "# think of the 1st dimension as the row and the index as the column\n",
    "two_dim = np.array([[1, 2, 3], [4, 5, 6]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f175b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(two_dim[1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ea0a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(two_dim[0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7a5b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# higher dimensional arrays are indexed similarly, the first integer represents the first dimension,\n",
    "# the second integer represents the second dimension and so on.\n",
    "three_dim = np.array([[[1, 2, 3], [4, 5, 6]], [[7, 8, 9], [10, 11, 12]]])\n",
    "print(three_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba1fd97",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(three_dim[0, 1, 2]) # prints third element of second array of first array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e23336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# above the 0 allows us to access the first 2D array...see below\n",
    "print(three_dim[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4836a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from there on the next two positions are just accessing values within the first 2D array\n",
    "print(three_dim[0, 1]) # this returns second row from first 2D array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0d9d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use negative indexing as well.\n",
    "# Here we access the last element of the last row of the last 2D array.\n",
    "print(three_dim[-1, -1, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58422107",
   "metadata": {},
   "outputs": [],
   "source": [
    "# and here we access the first element of the last row of the first 2D array\n",
    "print(three_dim[0, -1, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b470018",
   "metadata": {},
   "source": [
    "### Slicing ndarrays\n",
    "\n",
    "Slicing is also similar to what we've experienced with lists and tuples\n",
    "we slice with [start: end] or [start: end: step]\n",
    "as before, omitting the starting index assumes zero\n",
    "and omitting the end assumes the length of the array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653ddb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll skip an explanation of slicing 1D arrays and jump to higher dimensions\n",
    "two_dim = np.array([[1, 2, 3, 4], [5, 6, 7, 8]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "840831d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we're slicing from index 1 to 3 of the second dimension (dimension index 1)\n",
    "print(two_dim[1, 1:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de740b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we're accessing the last two values from both dimensions\n",
    "# This will return a 2D array\n",
    "print(two_dim[0:2, 2:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cafce3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the following does the same as the preceding line\n",
    "print(two_dim[:, 2:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3918719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3D arrays are sliced similarly\n",
    "three_dim = np.array([[[1, 2, 3, 4], [5, 6, 7, 8]], [[9, 10, 11, 12], [13, 14, 15, 16]]])\n",
    "print(three_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c0a3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accessing last two elements of last row of second 2D array.\n",
    "print(three_dim[1, 1, 2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f120c84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns a 2D array\n",
    "print(three_dim[0:2, 1, 1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a073719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns a 3D array\n",
    "print(three_dim[0:2, 0:2, 1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1452ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Types\n",
    "# Numpy arrays are homogenous, but multiple datatypes are supported.\n",
    "# Numpy supports strings (S), integers (i), floats (f), bools (b) and complex numbers (c)\n",
    "# and also has some additional data types such as:\n",
    "# unsigned integer (u), timedelta (m), datetime (M), object (O), unicode string (U)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d0ba21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# oftentimes you need to cast an entire array to another type\n",
    "# numpy offers the method astype() which takes the new type as a parameter and returns a copy.\n",
    "# datatypes can be specified with the single char version or the name. For example 'f' or float.\n",
    "\n",
    "an_array = np.array([1, 2, 3, 4, 5, 11])\n",
    "an_array = an_array.astype('S1')\n",
    "print(an_array.dtype)\n",
    "print(an_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85c3c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# notice the truncation that occurs when casting to single byte string\n",
    "\n",
    "an_array = an_array.astype('S2')\n",
    "print(an_array.dtype)\n",
    "print(an_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d2e8fa",
   "metadata": {},
   "source": [
    "### copy() and view() methods\n",
    "These concepts are related to the aliasing of variables\n",
    "\n",
    "In numpy we can use the copy() method to make copies of arrays.\n",
    "Changes made to the original or the copy have no impact on another.\n",
    "A view() of an array just points to the original array, so changes made\n",
    "to the original or the view will impact the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750ad840",
   "metadata": {},
   "outputs": [],
   "source": [
    "# .copy()\n",
    "an_array = np.array([1, 2, 3, 4])\n",
    "a_copy = an_array.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30634e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "an_array[0] = 99\n",
    "a_copy[1] = 99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99213deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(an_array)\n",
    "print(a_copy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b78be9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# .view()\n",
    "an_array = np.array([1, 2, 3, 4])\n",
    "a_view = an_array.view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2528a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "an_array[0] = 99\n",
    "a_view[1] = 99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e2d5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(an_array)\n",
    "print(a_view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3062bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can think about this in terms of ownership of the data.\n",
    "# A copy owns the data and a view does not.\n",
    "# Data ownership can be assessed using the base attribute of an ndarray.\n",
    "\n",
    "an_array = np.array([1, 2, 3, 4])\n",
    "a_copy = an_array.copy()\n",
    "a_view = an_array.view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177ffa3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the array owns the data the base attribute will return None\n",
    "# If not the base attribute returns a reference to the original object\n",
    "\n",
    "print(a_copy.base)\n",
    "print(a_view.base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c963b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we modify an element in the original array returned from the base attribute\n",
    "# it will modify the original array.\n",
    "\n",
    "a_view.base[0] = 99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42eab2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now if we print the original array, the copy and the view,\n",
    "# the original and the view will have been modified by the preceding statement.\n",
    "# this will have an impact on any views of the base array as well.\n",
    "\n",
    "print(an_array)\n",
    "print(a_copy)\n",
    "print(a_view)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a6f883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the shape attribute returns a tuple (of length .ndim) with the corresponding number of elements in that index\n",
    "one_dim = np.array([1, 2, 3, 4])\n",
    "two_dim = np.array([[1, 2, 3, 4], [5, 6, 7, 8]])\n",
    "three_dim = np.array([[[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]], [[1, 2, 3, 4], [5, 6, 7, 8], [9, 10, 11, 12]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576a357a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(one_dim.shape) # one dimension with 4 elements\n",
    "print(two_dim.shape) # two dimensions with 4 elements. Or two rows and 4 columns.\n",
    "print(three_dim.shape) # three dimensions. Two three x four 2D arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016b3c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape()\n",
    "# The reshape method allows us to change the shape of an array or add/remove elements from dimensions.\n",
    "# You can reshape into any array as long as you have enough elements to achieve that shape.\n",
    "# for example, if we had a 1D array of length 9 then we couldn't reshape into a 2D array of shape (2, 5)\n",
    "an_array = np.array([i for i in range(1, 21)])\n",
    "\n",
    "new_array = an_array.reshape(4, 5)\n",
    "print(new_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ee078d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that reshaping returns a view\n",
    "print(an_array.reshape(2, 5, 2).base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b52049",
   "metadata": {},
   "outputs": [],
   "source": [
    "an_array.reshape(2, 5, 2)[0, 0, 0] = 99\n",
    "print(an_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae922457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that we can avoid this by creating a copy of the view.\n",
    "one_dim = np.array([1, 2, 3, 4, 5, 6, 7, 8])\n",
    "two_dim = one_dim.reshape(4, 2).copy()\n",
    "two_dim[0, 0] = 99\n",
    "print(two_dim.base)\n",
    "print(two_dim)\n",
    "print(one_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55de24ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also initialize the values of the array generally\n",
    "\n",
    "# np.zeros() takes a shape and will initialize an ndarray\n",
    "print(np.zeros(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b8f35c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "three_dim_z = np.zeros((2,3,4))\n",
    "print(three_dim_z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d721ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.ones()\n",
    "print(np.ones(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17ffd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "two_dim_ones = np.ones((4,4))\n",
    "print(two_dim_ones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0875e0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.random.random()...continuous uniform draws\n",
    "print(np.random.random(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e9ff84",
   "metadata": {},
   "outputs": [],
   "source": [
    "two_dim_rand = np.random.random((4, 4))\n",
    "print(two_dim_rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172acbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.arange() similar to range()...takes start stop and step values\n",
    "\n",
    "three_dim = np.arange(1, 51).reshape(5, 2, 5)\n",
    "print(three_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a990b354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are a number of array methods that provide valuable aggregate information\n",
    "# .min(), .max(), .sum(), mean(), std()\n",
    "print(two_dim_rand.max())\n",
    "print(two_dim_rand.min())\n",
    "print(two_dim_rand.sum())\n",
    "print(two_dim_rand.mean())\n",
    "print(two_dim_rand.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e681e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the mean of first column of two_dim_rand\n",
    "print(two_dim_rand[:,0].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c8ca3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can specify the axis of the ndarray to accomplish this as well\n",
    "# axis 0 computes along rows and axis 1 computes along columns\n",
    "print(two_dim_rand.mean(axis=1)) # aggregates along column, so will return means for each row\n",
    "print(two_dim_rand.mean(axis=0)) # aggregates along rows, so will return means for each column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb2b949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterating over ndarrays\n",
    "\n",
    "# prints elements\n",
    "for i in np.array([i for i in range(10)]):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6193c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prints rows\n",
    "for i in np.arange(1,21).reshape(4, 5):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79706f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prints 2-D matrices\n",
    "np.random.seed(101)\n",
    "\n",
    "for i in np.random.random((2,5,2)):\n",
    "    print('element\\n', i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95358415",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nditer()\n",
    "# returns an iterator over the array\n",
    "\n",
    "np.random.seed(101)\n",
    "\n",
    "for i in np.nditer(np.random.random((2,5,2))):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac135b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(101)\n",
    "an_iterator = np.nditer(np.random.random((2,5,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4eb7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "next(an_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342f9565",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ndenumerate\n",
    "# similar to standard library enumerate function\n",
    "\n",
    "for i, j in np.ndenumerate(np.random.random((2,5,2))):\n",
    "    print(i, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "469c5e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ravel()\n",
    "# returns a 1D array representation of a higher dim data structure\n",
    "np.random.seed(101)\n",
    "\n",
    "np.ravel(np.random.random((2,5,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf31539",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### In-Class: Some Data Cleaning with Pandas\n",
    "\n",
    "+ Download the two csv’s posted in the files section of 2DU\n",
    "    - carnegie2021.csv\n",
    "    - us_census_regions_divisions.csv\n",
    "\n",
    "+ Read both files into pandas DataFrames (encoding = \"ISO-8859-1“ for the Carnegie file)\n",
    "\n",
    "+ Retain only basic2021 values of 15 and 16 (15 = Doctoral Very High Research, 16 = Doctoral High Research)\n",
    "\n",
    "+ Split the location feature from Carnegie into city and state columns.\n",
    "\n",
    "+ Merge the files in order to add the Region and Division features from census to Carnegie. \n",
    "\n",
    "+ Retain only the following columns:\n",
    "\t*unitid, name, city, state, Region, Division, basic2018, basic2021, pdnfrstaff, facnum, socsc_rsd, hum_rsd, \tstem_rsd, oth_rsd* \n",
    "\n",
    "+ Create ranking features for the last six variables (*pdnfrstaff, facnum, socsc_rsd, hum_rsd, stem_rsd, oth_rsd*).\n",
    "\n",
    "+ Import StandardScaler from sklearn.preprocessing and fit_transform this scaler on the ranked columns….or just implement a z score manually.\n",
    "\n",
    "+ Make two composite scores according to the following arbitrary weighting scheme:\n",
    "    - HR_composite: a 50/50 weighted avg of the z scores for pdnfrstaff and facnum\n",
    "    - RSD_composite: a 40/20/20/20 weighted avg of the z scores for stem_rsd, socsc_rsd, hum_rsd, oth_rsd\n",
    "\n",
    "+ Access the names of institutions that had a high research classification (16) in 2018 and very high (15) in 2021.\n",
    "\n",
    "+ What states have the most 'Doctoral Very High Research' institutions?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "46c7e8a6",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xf3 in position 123923: invalid continuation byte",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Download the two csv’s posted in the files section of 2DU\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# carnegie2021.csv\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# us_census_regions_divisions.csv\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m carnegie2021 \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcarnegie2021.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m us_census_regions_divisions \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mus_census_regions_divisions.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/parsers/readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    665\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    666\u001b[0m     dialect,\n\u001b[1;32m    667\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    676\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    677\u001b[0m )\n\u001b[1;32m    678\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 680\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/parsers/readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    572\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    574\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 575\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/parsers/readers.py:934\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    931\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    933\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 934\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1236\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1233\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m   1235\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1236\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1237\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1238\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/io/parsers/c_parser_wrapper.py:75\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     72\u001b[0m     kwds\u001b[38;5;241m.\u001b[39mpop(key, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     74\u001b[0m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m ensure_dtype_objs(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m---> 75\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader \u001b[38;5;241m=\u001b[39m \u001b[43mparsers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTextReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munnamed_cols \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39munnamed_cols\n\u001b[1;32m     79\u001b[0m \u001b[38;5;66;03m# error: Cannot determine type of 'names'\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:544\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:633\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._get_header\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:847\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/pandas/_libs/parsers.pyx:1952\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xf3 in position 123923: invalid continuation byte"
     ]
    }
   ],
   "source": [
    "# Download the two csv’s posted in the files section of 2DU\n",
    "# carnegie2021.csv\n",
    "# us_census_regions_divisions.csv\n",
    "import pandas as pd\n",
    "carnegie2021 = pd.read_csv('carnegie2021.csv')\n",
    "us_census_regions_divisions = pd.read_csv('us_census_regions_divisions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff5e89c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
